"""
app.py

ÎœÎ¹Î± ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Î±Î½Î±Î³Î½ÏÏÎ¹ÏƒÎ·Ï‚ Î¼Î½Î·Î¼ÎµÎ¯Ï‰Î½ (landmarks) Î²Î±ÏƒÎ¹ÏƒÎ¼Î­Î½Î· ÏƒÎµ Î­Î½Î± fine-tuned CLIP Î¼Î¿Î½Ï„Î­Î»Î¿.
Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ Ï„Î¿ Streamlit Î³Î¹Î± Ï„Î¿ UI ÎºÎ±Î¹ Ï€ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬ Î±Î½Ï„Î»ÎµÎ¯ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ Î±Ï€ÏŒ Ï„Î· Wikipedia.
"""

import streamlit as st
from PIL import Image
import torch
import torchvision.transforms as transforms
import os
import json
import wikipedia

# -----------------------------------------
# 1) Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® Ï„Î·Ï‚ ÎºÎ»Î¬ÏƒÎ·Ï‚ Î±Ï€ÏŒ Ï„Î¿ Python Î±ÏÏ‡ÎµÎ¯Î¿
# -----------------------------------------
# Î£Ï„Î¿ Ï†Î¬ÎºÎµÎ»Î¿ "models", Î²ÏÎ¯ÏƒÎºÎµÏ„Î±Î¹ Ï„Î¿ "clip_classifier.py",
# ÏŒÏ€Î¿Ï… Î¿ÏÎ¯Î¶ÎµÏ„Î±Î¹ Î· ÎºÎ»Î¬ÏƒÎ· CLIPWithClassifier (nn.Module).
from models.clip_classifier import CLIPWithClassifier


# -----------------------------------------
# 2) Î£Ï…Î½Î¬ÏÏ„Î·ÏƒÎ· Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ Ï„Î¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï…
# -----------------------------------------
@st.cache_resource
def load_model():
    """
    Î¦Î¿ÏÏ„ÏÎ½ÎµÎ¹ Ï„Î¿ CLIP Image Encoder + Ï„Î¿ Linear Classifier (CLIPWithClassifier) 
    ÎºÎ±Î¹ Ï„Î± Î²Î¬ÏÎ· Î±Ï€ÏŒ Ï„Î¿ .pth checkpoint. 

    Returns:
        model (nn.Module): Î¤Î¿ CLIPWithClassifier ÏƒÎµ ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· .eval().
        device (str): Î£Ï…ÏƒÎºÎµÏ…Î® (cuda Î® cpu) Î³Î¹Î± Ï‡ÏÎ®ÏƒÎ· ÏƒÏ„Î¿ inference.
    """
    device = "cuda" if torch.cuda.is_available() else "cpu"

    import clip  # pip install git+https://github.com/openai/CLIP.git
    clip_model, _ = clip.load("ViT-B/32", device=device, jit=False)
    clip_model = clip_model.float()

    # ÎŸ Î±ÏÎ¹Î¸Î¼ÏŒÏ‚ Ï„Ï‰Î½ ÎºÎ»Î¬ÏƒÎµÏ‰Î½ Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÏƒÏ…Î¼Ï€Î¯Ï€Ï„ÎµÎ¹ Î¼Îµ Î±Ï…Ï„ÏŒÎ½ Ï€Î¿Ï… Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®Î¸Î·ÎºÎµ ÏƒÏ„Î¿ training.
    num_classes = 1434  # Î Î±ÏÎ¬Î´ÎµÎ¹Î³Î¼Î±

    model = CLIPWithClassifier(
        clip_model=clip_model,
        num_classes=num_classes,
        dropout_rate=0.1,
        freeze_clip=False
    ).to(device)

    checkpoint_path = "models/BestClipModel.pth"  # Î ÏÎ¿ÏƒÎ±ÏÎ¼ÏŒÏƒÏ„Îµ Ï„Î¿ path
    checkpoint = torch.load(checkpoint_path, map_location=device)
    model.load_state_dict(checkpoint["model_state_dict"])
    model.eval()

    return model, device


# -----------------------------------------
# 3) Î£Ï…Î½Î¬ÏÏ„Î·ÏƒÎ· Ï†ÏŒÏÏ„Ï‰ÏƒÎ·Ï‚ Ï„Î¿Ï… label_mapping
# -----------------------------------------
@st.cache_resource
def load_label_mapping():
    """
    Î¦Î¿ÏÏ„ÏÎ½ÎµÎ¹ Ï„Î¿ JSON Ï€Î¿Ï… Ï‡Î±ÏÏ„Î¿Î³ÏÎ±Ï†ÎµÎ¯ (encoded_label -> friendly_name).
    Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯Ï„Î±Î¹ ÏƒÏ„Î¿ Notebook, ÏƒÏ…Î½Î®Î¸Ï‰Ï‚ Î±Ï€ÏŒ: 
    (encoded_label -> landmark_id) + (landmark_id -> categoryURL) -> friendly_name.

    Returns:
        label_map (dict[int,str]): Î›ÎµÎ¾Î¹ÎºÏŒ ÏŒÏ€Î¿Ï… Ï„Î¿ ÎºÎ»ÎµÎ¹Î´Î¯ ÎµÎ¯Î½Î±Î¹ Ï„Î¿ int encoded_label
                                   ÎºÎ±Î¹ Î· Ï„Î¹Î¼Î® ÎµÎ¯Î½Î±Î¹ Ï„Î¿ Î±Î½Î¸ÏÏÏ€Î¹Î½Î¿ ÏŒÎ½Î¿Î¼Î± Ï„Î¿Ï… landmark.
    """
    mapping_json_path = "data/label_mapping.json"
    with open(mapping_json_path, "r", encoding="utf-8") as f:
        mapping = json.load(f)

    label_map = {int(k): v for k, v in mapping.items()}
    return label_map


# -----------------------------------------
# 4) Î£Ï…Î½Î¬ÏÏ„Î·ÏƒÎ· Î³Î¹Î± Î»Î®ÏˆÎ· Ï€ÎµÏÎ¯Î»Î·ÏˆÎ·Ï‚ Î±Ï€ÏŒ Wikipedia (Ï€ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÎ®)
# -----------------------------------------
def get_wiki_summary(title: str, lang="en", sentences=2):
    """
    Î Î±Î¯ÏÎ½ÎµÎ¹ ÏƒÏÎ½Ï„Î¿Î¼Î· Ï€ÎµÏÎ¯Î»Î·ÏˆÎ· Î±Ï€ÏŒ Ï„Î· Wikipedia Î³Î¹Î± Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î¿ "title".

    Args:
        title (str): Î¤Î¿ Î»Î®Î¼Î¼Î± Î³Î¹Î± Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·.
        lang (str): Î“Î»ÏÏƒÏƒÎ± (default="en").
        sentences (int): Î ÏŒÏƒÎµÏ‚ Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚ ÏƒÏ„Î·Î½ Ï€ÎµÏÎ¯Î»Î·ÏˆÎ·.

    Returns:
        (str or None): 
            - ÎšÎµÎ¯Î¼ÎµÎ½Î¿ Ï€ÎµÏÎ¯Î»Î·ÏˆÎ·Ï‚ Î±Î½ Î²ÏÎµÎ¸ÎµÎ¯,
            - None Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ disambiguation Î® ÏƒÏ†Î¬Î»Î¼Î± ÏƒÎµÎ»Î¯Î´Î±Ï‚.
    """
    try:
        wikipedia.set_lang(lang)
        summary = wikipedia.summary(title, sentences=sentences)
        return summary
    except wikipedia.DisambiguationError:
        return None
    except wikipedia.PageError:
        return None
    except Exception:
        return None


# -----------------------------------------
# 5) Î£Ï…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚ Î³Î¹Î± Preprocessing & Predict
# -----------------------------------------
def preprocess_image(image: Image.Image) -> torch.Tensor:
    """
    ÎœÎµÏ„Î±ÏƒÏ‡Î·Î¼Î±Ï„Î¹ÏƒÎ¼Î¿Î¯ Ï€Î¿Ï… Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®Î¸Î·ÎºÎ±Î½ ÏƒÏ„Î¿ training:
      - Resize (224,224)
      - ToTensor
      - Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]).

    Args:
        image (PIL.Image): Î•Î¹ÎºÏŒÎ½Î± ÏƒÎµ Î¼Î¿ÏÏ†Î® PIL.

    Returns:
        torch.Tensor: Î£Ï‡Î®Î¼Î± [1,3,224,224].
    """
    preprocess = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225]),
    ])
    return preprocess(image).unsqueeze(0)

def predict(image_tensor: torch.Tensor, model: torch.nn.Module, device: str):
    """
    ÎšÎ¬Î½ÎµÎ¹ forward pass ÏƒÏ„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ (Ï‡Ï‰ÏÎ¯Ï‚ gradient) ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ top-5 ÎºÎ»Î¬ÏƒÎµÎ¹Ï‚/Ï€Î¹Î¸Î±Î½ÏŒÏ„Î·Ï„ÎµÏ‚.

    Args:
        image_tensor (torch.Tensor): shape [1,3,224,224].
        model (nn.Module): CLIPWithClassifier ÏƒÎµ eval().
        device (str): 'cuda' Î® 'cpu'.

    Returns:
        (np.array, np.array):
            top_probs: ÎŸÎ¹ top-5 Ï€Î¹Î¸Î±Î½ÏŒÏ„Î·Ï„ÎµÏ‚
            top_classes: ÎŸÎ¹ top-5 Î±Î½Ï„Î¯ÏƒÏ„Î¿Î¹Ï‡ÎµÏ‚ ÎºÎ»Î¬ÏƒÎµÎ¹Ï‚
    """
    with torch.no_grad():
        logits = model(image_tensor.to(device))
        probs = torch.softmax(logits, dim=1)
        top_probs, top_classes = probs.topk(5, dim=1)
        return top_probs.cpu().numpy()[0], top_classes.cpu().numpy()[0]


# -----------------------------------------
# 6) Î£Ï…Î½Î¬ÏÏ„Î·ÏƒÎ·: decode_predictions (Î¼Îµ Wiki)
# -----------------------------------------
def decode_predictions(top_probs, top_classes, label_map, wiki_lang="en"):
    """
    ÎœÎµÏ„Î±Ï„ÏÎ­Ï€ÎµÎ¹ Ï„Î¹Ï‚ top-5 Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ (probabilities & class indices)
    ÏƒÎµ Ï†Î¹Î»Î¹ÎºÏŒ ÎºÎµÎ¯Î¼ÎµÎ½Î¿. ÎšÎ±Î»ÎµÎ¯ Ï€ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬ wikipedia.summary.

    Args:
        top_probs (np.array): Ï€.Ï‡. [0.45,0.22,0.15,0.10,0.08]
        top_classes (np.array): Ï€.Ï‡. [23,89,17,104,356]
        label_map (dict[int,str]): mapping int->str (0->"Eiffel Tower" ÎºÎ»Ï€.)
        wiki_lang (str): Î“Î»ÏÏƒÏƒÎ± Wikipedia. Default="en"

    Returns:
        list[str]: Î›Î¯ÏƒÏ„Î± Î±Ï€ÏŒ strings Î³Î¹Î± ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·.
    """
    results = []
    for prob, cls_idx in zip(top_probs, top_classes):
        landmark_name = label_map.get(cls_idx, f"Landmark_{cls_idx}")
        summary = get_wiki_summary(landmark_name, lang=wiki_lang, sentences=2)
        if summary:
            text = f"**{landmark_name}** - {prob*100:.2f}%\n\n{summary}"
        else:
            text = f"**{landmark_name}** - {prob*100:.2f}%\n\n(No summary found)"
        results.append(text)
    return results


# -----------------------------------------
# 7) Streamlit UI - Main Î»Î¿Î³Î¹ÎºÎ®
# -----------------------------------------
def main():
    """
    Î’Î±ÏƒÎ¹ÎºÎ® ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Ï„Î¿Ï… Streamlit app.
    Î¦Î¿ÏÏ„ÏÎ½ÎµÎ¹ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ & Ï„Î¿ label mapping, Ï€ÏÎ¿ÏƒÏ†Î­ÏÎµÎ¹ Upload/Camera,
    ÎºÎ±Î¹ ÎµÎ¼Ï†Î±Î½Î¯Î¶ÎµÎ¹ Ï„Î¹Ï‚ top-5 Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ CLIP.
    """
    st.title("Landmark Recognition App \U0001F5BC")
    st.markdown("""
    ÎšÎ±Î»Ï‰ÏƒÎ®ÏÎ¸Î±Ï„Îµ ÏƒÏ„Î·Î½ ÎµÏ†Î±ÏÎ¼Î¿Î³Î® **Landmark Recognition**!  
    Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ Î­Î½Î± Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÎ¼Î­Î½Î¿ (fine-tuned) CLIP Î¼Î¿Î½Ï„Î­Î»Î¿ Î³Î¹Î± Î½Î± ÎµÎ½Ï„Î¿Ï€Î¯ÏƒÎµÎ¹
    Î¼Î½Î·Î¼ÎµÎ¯Î±/Ï„Î¿Ï€Î¿Î¸ÎµÏƒÎ¯ÎµÏ‚ ÏƒÎµ Î¿Ï€Î¿Î¹Î±Î´Î®Ï€Î¿Ï„Îµ ÎµÎ¹ÎºÏŒÎ½Î±, ÎµÎ¼Ï†Î±Î½Î¯Î¶Î¿Î½Ï„Î±Ï‚ ÎºÎ±Î¹ ÏƒÏÎ½Ï„Î¿Î¼Î· Ï€ÎµÏÎ¯Î»Î·ÏˆÎ·
    Î±Ï€ÏŒ Ï„Î· Wikipedia (Ï€ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬).
    """)

    st.sidebar.title("Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚ & Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚")
    st.sidebar.markdown("""
    **Î Î·Î³Î® Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½**: Google Landmarks Dataset v2  
    **ÎœÎ¿Î½Ï„Î­Î»Î¿**: CLIP (ViT-B/32) + Linear Classifier  
    **Î§ÏÎ®ÏƒÎ·**: Î•Ï€Î¹Î»Î­Î¾Ï„Îµ ÎµÎ¹ÎºÏŒÎ½Î± (Upload/Camera).  
    """)

    # Î¦Î¿ÏÏ„ÏÎ½Î¿Ï…Î¼Îµ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ & Ï„Î¿ label mapping
    model, device = load_model()
    label_map = load_label_mapping()

    # Î•Ï€Î¹Î»Î¿Î³Î® Ï€Î·Î³Î®Ï‚ ÎµÎ¹ÎºÏŒÎ½Î±Ï‚
    st.write("### 1) Î•Ï€Î¹Î»Î¿Î³Î® Î Î·Î³Î®Ï‚ Î•Î¹ÎºÏŒÎ½Î±Ï‚")
    option = st.radio(
        "Î ÏÏ‚ Î¸Î­Î»ÎµÏ„Îµ Î½Î± ÎµÎ¹ÏƒÎ¬Î³ÎµÏ„Îµ Ï„Î·Î½ ÎµÎ¹ÎºÏŒÎ½Î±;", 
        ("Upload", "Camera"), 
        index=0
    )

    image = None
    if option == "Upload":
        uploaded_file = st.file_uploader("Î‘Î½ÎµÎ²Î¬ÏƒÏ„Îµ Î±ÏÏ‡ÎµÎ¯Î¿ (.jpg Î® .png)", type=["jpg", "png"])
        if uploaded_file is not None:
            try:
                image = Image.open(uploaded_file).convert("RGB")
            except Exception:
                st.error("Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î¿ Î¬Î½Î¿Î¹Î³Î¼Î± Ï„Î·Ï‚ ÎµÎ¹ÎºÏŒÎ½Î±Ï‚. Î”Î¿ÎºÎ¹Î¼Î¬ÏƒÏ„Îµ Î¾Î±Î½Î¬.")
    else:
        camera_file = st.camera_input("Î¤ÏÎ±Î²Î®Î¾Ï„Îµ Ï†Ï‰Ï„Î¿Î³ÏÎ±Ï†Î¯Î± Î±Ï€ÏŒ Ï„Î·Î½ ÎºÎ¬Î¼ÎµÏÎ±")
        if camera_file is not None:
            try:
                image = Image.open(camera_file).convert("RGB")
            except Exception:
                st.error("Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î¿ Î¬Î½Î¿Î¹Î³Î¼Î± Ï„Î·Ï‚ ÎµÎ¹ÎºÏŒÎ½Î±Ï‚ Î±Ï€ÏŒ Ï„Î·Î½ ÎºÎ¬Î¼ÎµÏÎ±.")

    if image is not None:
        st.write("### 2) Î ÏÎ¿ÎµÏ€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ· Î•Î¹ÎºÏŒÎ½Î±Ï‚")
        st.image(image, caption="Î•Ï€Î¹Î»ÎµÎ³Î¼Î­Î½Î· Î•Î¹ÎºÏŒÎ½Î±", use_container_width=True)

        st.write("### 3) Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î‘Î½Î±Î³Î½ÏÏÎ¹ÏƒÎ·Ï‚")
        with st.spinner("Î Î±ÏÎ±ÎºÎ±Î»Ï Ï€ÎµÏÎ¹Î¼Î­Î½ÎµÏ„Îµâ€¦ Î‘Î½Î±Î³Î½Ï‰ÏÎ¯Î¶Î¿Ï…Î¼Îµ Ï„Î¿ Î¼Î½Î·Î¼ÎµÎ¯Î¿!"):
            # Preprocess & Predict
            image_tensor = preprocess_image(image)
            top_probs, top_classes = predict(image_tensor, model, device)
            # Decode Î¼Îµ Wiki info
            results = decode_predictions(top_probs, top_classes, label_map, wiki_lang="en")

        st.success("Î— Î±Î½Î±Î³Î½ÏÏÎ¹ÏƒÎ· Î¿Î»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ Î¼Îµ ÎµÏ€Î¹Ï„Ï…Ï‡Î¯Î±!")
        st.subheader("Top-5 Î ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚:")
        for idx, line in enumerate(results, start=1):
            st.markdown(f"**#{idx}**\n{line}")
            st.markdown("---")
    else:
        st.info("Î‘Î½ÎµÎ²Î¬ÏƒÏ„Îµ Î® Ï„ÏÎ±Î²Î®Î¾Ï„Îµ Î¼Î¹Î± Ï†Ï‰Ï„Î¿Î³ÏÎ±Ï†Î¯Î± Î³Î¹Î± Î½Î± Î¾ÎµÎºÎ¹Î½Î®ÏƒÎµÎ¹ Î· Î±Î½Î±Î³Î½ÏÏÎ¹ÏƒÎ·.")


# ----------------------------
# 8) Footer
# ----------------------------
def custom_footer():
    """
    Î•Î¼Ï†Î±Î½Î¯Î¶ÎµÎ¹ Î­Î½Î± custom footer ÏƒÏ„Î¿ ÎºÎ¬Ï„Ï‰ Î¼Î­ÏÎ¿Ï‚ Ï„Î·Ï‚ ÏƒÎµÎ»Î¯Î´Î±Ï‚,
    Î¼Îµ emojis ÎºÎ±Î¹ links.
    """
    footer_html = """
    <hr/>
    <div style="text-align: center; padding: 10px;">
        <p>ğŸ”§ <strong>Î ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÏƒÏ„Î®Ï‚:</strong> 
            <a href="mailto:Th4nosMylonas@gmail.com" target="_blank">Î˜Î±Î½Î¬ÏƒÎ·Ï‚ ÎœÏ…Î»Ï‰Î½Î¬Ï‚</a> &nbsp;|&nbsp;
            ğŸŒ <strong>GitHub:</strong> 
            <a href="https://github.com/Th4nosMyl" target="_blank">Th4nosMyl</a>
        </p>
        <p>Â© 2024 Landmark Lens App &nbsp;|&nbsp; ğŸ›ï¸ ÎšÎ±Ï„Î±ÏƒÎºÎµÏ…Î®: 
           <em>CLIP Fine-Tuning</em></p>
    </div>
    """
    st.markdown(footer_html, unsafe_allow_html=True)


# Î£Î·Î¼ÎµÎ¯Î¿ Î•ÎºÎºÎ¯Î½Î·ÏƒÎ·Ï‚ Ï„Î¿Ï… Streamlit App
if __name__ == "__main__":
    main()
    custom_footer()  # Î•Î¼Ï†Î±Î½Î¯Î¶ÎµÎ¹ Ï„Î¿ footer ÏƒÏ„Î¿ Ï„Î­Î»Î¿Ï‚
